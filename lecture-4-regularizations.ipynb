{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` comes with a few small standard datasets that do not require to download any file from some external website. The dataset is usually downloaded in a `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_iris()\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a `DataFrame` using the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "iris.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `sepal width`, `petal length`, and `petal width` to predict `sepal length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0               3.5                1.4               0.2\n",
       "1               3.0                1.4               0.2\n",
       "2               3.2                1.3               0.2\n",
       "3               3.1                1.5               0.2\n",
       "4               3.6                1.4               0.2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features\n",
    "X = iris.iloc[:, 1:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5.1\n",
       "1    4.9\n",
       "2    4.7\n",
       "3    4.6\n",
       "4    5.0\n",
       "Name: sepal length (cm), dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target\n",
    "y = iris.iloc[:, 0]\n",
    "y.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization / Scaling\n",
    "\n",
    "Since we will be using `SGDRegressor`, it is necessary that all the features are scaled similarly. For this, we will use the `StandardScaler` or the `MinMaxScaler`. You can find more about feature scaling [here](https://scikit-learn.org/stable/modules/preprocessing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "std_scaler = StandardScaler()\n",
    "\n",
    "X_new_mm = mm_scaler.fit_transform(X)\n",
    "X_new_std = std_scaler.fit_transform(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all the features are now between $0$ and $1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0          0.625000           0.067797          0.041667\n",
       "1          0.416667           0.067797          0.041667\n",
       "2          0.500000           0.050847          0.041667\n",
       "3          0.458333           0.084746          0.041667\n",
       "4          0.666667           0.067797          0.041667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_new_mm, columns=data['feature_names'][1:]).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, all the features after standard scaling have now mean $0$ and standard deviation $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.019004</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.397064</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.098217</td>\n",
       "      <td>-1.283389</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.249201</td>\n",
       "      <td>-1.340227</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0          1.019004          -1.340227         -1.315444\n",
       "1         -0.131979          -1.340227         -1.315444\n",
       "2          0.328414          -1.397064         -1.315444\n",
       "3          0.098217          -1.283389         -1.315444\n",
       "4          1.249201          -1.340227         -1.315444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_new_std, columns=data['feature_names'][1:]).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_new_mm,\n",
    "    y,\n",
    "    train_size=0.80,\n",
    "    random_state=25,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 3)\n",
      "(30, 3)\n",
      "(120,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(\n",
    "    fit_intercept=False,\n",
    "    loss='squared_error',\n",
    "    penalty='l1',\n",
    "    alpha=0.5,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1e-3,\n",
    "    learning_rate='constant',\n",
    "    eta0=0.01,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3.49, NNZs: 3, Bias: 0.000000, T: 108, Avg. loss: 10.626335\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.42, NNZs: 3, Bias: 0.000000, T: 216, Avg. loss: 4.338255\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 6.63, NNZs: 3, Bias: 0.000000, T: 324, Avg. loss: 2.634900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7.54, NNZs: 3, Bias: 0.000000, T: 432, Avg. loss: 2.031096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.28, NNZs: 3, Bias: 0.000000, T: 540, Avg. loss: 1.751867\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.94, NNZs: 3, Bias: 0.000000, T: 648, Avg. loss: 1.618806\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.54, NNZs: 3, Bias: 0.000000, T: 756, Avg. loss: 1.519056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 10.11, NNZs: 3, Bias: 0.000000, T: 864, Avg. loss: 1.461422\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 10.64, NNZs: 3, Bias: 0.000000, T: 972, Avg. loss: 1.398808\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.15, NNZs: 3, Bias: 0.000000, T: 1080, Avg. loss: 1.369630\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 11.64, NNZs: 3, Bias: 0.000000, T: 1188, Avg. loss: 1.342106\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 12.11, NNZs: 3, Bias: 0.000000, T: 1296, Avg. loss: 1.324280\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 12.57, NNZs: 3, Bias: 0.000000, T: 1404, Avg. loss: 1.296143\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 13.00, NNZs: 3, Bias: 0.000000, T: 1512, Avg. loss: 1.270802\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 13.42, NNZs: 3, Bias: 0.000000, T: 1620, Avg. loss: 1.258610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 13.83, NNZs: 3, Bias: 0.000000, T: 1728, Avg. loss: 1.242983\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 14.22, NNZs: 3, Bias: 0.000000, T: 1836, Avg. loss: 1.210934\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 14.61, NNZs: 3, Bias: 0.000000, T: 1944, Avg. loss: 1.208507\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 14.98, NNZs: 3, Bias: 0.000000, T: 2052, Avg. loss: 1.212365\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 15.35, NNZs: 3, Bias: 0.000000, T: 2160, Avg. loss: 1.205367\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 15.70, NNZs: 3, Bias: 0.000000, T: 2268, Avg. loss: 1.171261\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 16.05, NNZs: 3, Bias: 0.000000, T: 2376, Avg. loss: 1.181775\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 16.39, NNZs: 3, Bias: 0.000000, T: 2484, Avg. loss: 1.175427\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 16.72, NNZs: 3, Bias: 0.000000, T: 2592, Avg. loss: 1.163584\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 17.05, NNZs: 3, Bias: 0.000000, T: 2700, Avg. loss: 1.161065\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 17.37, NNZs: 3, Bias: 0.000000, T: 2808, Avg. loss: 1.159247\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 17.68, NNZs: 3, Bias: 0.000000, T: 2916, Avg. loss: 1.149770\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 17.99, NNZs: 3, Bias: 0.000000, T: 3024, Avg. loss: 1.130876\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 18.29, NNZs: 3, Bias: 0.000000, T: 3132, Avg. loss: 1.163232\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 18.59, NNZs: 3, Bias: 0.000000, T: 3240, Avg. loss: 1.144464\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 18.88, NNZs: 3, Bias: 0.000000, T: 3348, Avg. loss: 1.132873\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 19.17, NNZs: 3, Bias: 0.000000, T: 3456, Avg. loss: 1.153156\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 19.45, NNZs: 3, Bias: 0.000000, T: 3564, Avg. loss: 1.098681\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 19.73, NNZs: 3, Bias: 0.000000, T: 3672, Avg. loss: 1.132769\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 20.01, NNZs: 3, Bias: 0.000000, T: 3780, Avg. loss: 1.148610\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 20.28, NNZs: 3, Bias: 0.000000, T: 3888, Avg. loss: 1.131889\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 20.55, NNZs: 3, Bias: 0.000000, T: 3996, Avg. loss: 1.126302\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 20.82, NNZs: 3, Bias: 0.000000, T: 4104, Avg. loss: 1.135823\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 21.08, NNZs: 3, Bias: 0.000000, T: 4212, Avg. loss: 1.116708\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 21.34, NNZs: 3, Bias: 0.000000, T: 4320, Avg. loss: 1.117813\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 21.60, NNZs: 3, Bias: 0.000000, T: 4428, Avg. loss: 1.115851\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 21.85, NNZs: 3, Bias: 0.000000, T: 4536, Avg. loss: 1.129518\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 22.10, NNZs: 3, Bias: 0.000000, T: 4644, Avg. loss: 1.114897\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 22.35, NNZs: 3, Bias: 0.000000, T: 4752, Avg. loss: 1.130816\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 22.59, NNZs: 3, Bias: 0.000000, T: 4860, Avg. loss: 1.095599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 22.83, NNZs: 3, Bias: 0.000000, T: 4968, Avg. loss: 1.112918\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 23.07, NNZs: 3, Bias: 0.000000, T: 5076, Avg. loss: 1.102965\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 23.31, NNZs: 3, Bias: 0.000000, T: 5184, Avg. loss: 1.097860\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 23.54, NNZs: 3, Bias: 0.000000, T: 5292, Avg. loss: 1.127060\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 23.78, NNZs: 3, Bias: 0.000000, T: 5400, Avg. loss: 1.115638\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 24.01, NNZs: 3, Bias: 0.000000, T: 5508, Avg. loss: 1.121219\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 24.23, NNZs: 3, Bias: 0.000000, T: 5616, Avg. loss: 1.070120\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 24.46, NNZs: 3, Bias: 0.000000, T: 5724, Avg. loss: 1.115046\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 24.68, NNZs: 3, Bias: 0.000000, T: 5832, Avg. loss: 1.081893\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 24.90, NNZs: 3, Bias: 0.000000, T: 5940, Avg. loss: 1.090695\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 25.12, NNZs: 3, Bias: 0.000000, T: 6048, Avg. loss: 1.125791\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 25.34, NNZs: 3, Bias: 0.000000, T: 6156, Avg. loss: 1.102503\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 25.56, NNZs: 3, Bias: 0.000000, T: 6264, Avg. loss: 1.112211\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 25.78, NNZs: 3, Bias: 0.000000, T: 6372, Avg. loss: 1.096264\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 25.98, NNZs: 3, Bias: 0.000000, T: 6480, Avg. loss: 1.062134\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 26.19, NNZs: 3, Bias: 0.000000, T: 6588, Avg. loss: 1.093981\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 61 epochs took 0.02 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(alpha=0.5, early_stopping=True, fit_intercept=False,\n",
       "             learning_rate=&#x27;constant&#x27;, max_iter=500, n_iter_no_change=10,\n",
       "             penalty=&#x27;l1&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(alpha=0.5, early_stopping=True, fit_intercept=False,\n",
       "             learning_rate=&#x27;constant&#x27;, max_iter=500, n_iter_no_change=10,\n",
       "             penalty=&#x27;l1&#x27;, verbose=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor(alpha=0.5, early_stopping=True, fit_intercept=False,\n",
       "             learning_rate='constant', max_iter=500, n_iter_no_change=10,\n",
       "             penalty='l1', verbose=2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.22152497, 3.95283961, 0.82921081])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MAE:  1.3364790091582843\n",
      "Training MSE:  2.25597657011425\n",
      "Training RMSE:  1.5019908688518215\n"
     ]
    }
   ],
   "source": [
    "# Training Data Evaluation\n",
    "training_predictions = model.predict(X_train)\n",
    "\n",
    "training_mae = mean_absolute_error(y_train, training_predictions)\n",
    "training_mse = mean_squared_error(y_train, training_predictions)\n",
    "training_rmse = np.sqrt(training_mse)\n",
    "\n",
    "print(\"Training MAE: \", training_mae)\n",
    "print(\"Training MSE: \", training_mse)\n",
    "print(\"Training RMSE: \", training_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE:  1.4687237267988595\n",
      "Test MSE:  2.7527521500691408\n",
      "Test RMSE:  1.659141992136038\n"
     ]
    }
   ],
   "source": [
    "# Test Data Evaluation\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "print(\"Test MAE: \", test_mae)\n",
    "print(\"Test MSE: \", test_mse)\n",
    "print(\"Test RMSE: \", test_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb3c4fd9fe25374e0159eca8b8e2d468e8cbc895c30c0bc56e2d3921906cc884"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
