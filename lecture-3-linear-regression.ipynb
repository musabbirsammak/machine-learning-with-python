{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Linear Dataset\n",
    "We will create a dummy dataset with $1$ feature and $1$ target variable. There will be a linear relationship between the feature and the target, but with some noise added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature\n",
    "X = 2 * np.random.rand(1000, 1)\n",
    "# Target. The relationship is y = 3x + 4 + some random noise\n",
    "y = 4 + 3 * X + np.random.randn(1000, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see below, the relationship between the feature and the target is not perfectly linear. However, it is evident that there is an overall linear trend among them. For example, as the value of $X$ increases, the value of $y$ also increases linearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, alpha=0.25, c=\"purple\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Scatter plot of X (feature) and y (target)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Custom Gradient Descent Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intitialize hyperparameters\n",
    "w1 = 0.01\n",
    "w0 = 0.02\n",
    "alpha = 0.01\n",
    "epoch = 25\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "losses = []\n",
    "valid_losses = []\n",
    "for i in range(epoch):\n",
    "    # calculate training loss\n",
    "    y_hat = w1*X_train + w0\n",
    "    loss = np.mean((y_train - y_hat) ** 2)\n",
    "    losses.append(loss)\n",
    "\n",
    "    # calculate validation loss\n",
    "    y_hat_valid = w1*X_valid + w0\n",
    "    valid_loss = np.mean((y_valid - y_hat_valid) ** 2)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    print(f\"Epoch {i+1}: Training Error: {loss} | Validation Error: {valid_loss}\")\n",
    "\n",
    "    # TODO: early stopping\n",
    "\n",
    "    # calculate the derivates\n",
    "    dl_dw1 = -2 * X_train * (y_train - y_hat)\n",
    "    dl_w0 = -2 * (y_train - y_hat)\n",
    "    \n",
    "    # update weights\n",
    "    w1 = w1 - alpha * np.mean(dl_dw1)\n",
    "    w1 = w1 - alpha * np.mean(dl_dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(epoch) + 1, losses, label=\"Training Error\")\n",
    "plt.scatter(np.arange(epoch) + 1, valid_losses, label=\"Validation error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Epoch Vs. Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"w1: {w1}, & w0: {w0}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model Using Normal Equation\n",
    "We will be using the `LinearRegression` class from `sklearn` module to develop a linear model. You can find more about the available parameters [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(\n",
    "    fit_intercept=False,\n",
    "    copy_X=True,\n",
    "    n_jobs=-1,\n",
    "    positive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of feature: ', model.coef_)\n",
    "print('Intercept: ', model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "\n",
    "plt.scatter(X, y, alpha=0.75, edgecolors='black', label='Actual Value')\n",
    "plt.scatter(X, predictions, alpha=0.75, edgecolors='black', label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Model Using Gradient Descent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will build a linear model using stochastic gradient descent. We will use the `SGDRegressor` from `sklearn` module. You will find more about the available parameters [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SGDRegressor(\n",
    "    fit_intercept=True,\n",
    "    loss='squared_error',\n",
    "    penalty='l1',\n",
    "    alpha=0.5,\n",
    "    max_iter=1000,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1e-3,\n",
    "    learning_rate='constant',\n",
    "    eta0=0.0001,\n",
    "    verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient of feature: ', model2.coef_.item())\n",
    "print('Intercept: ', model2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data = np.array([1.24])\n",
    "\n",
    "print(model.predict([fake_data]))\n",
    "print(model2.predict([fake_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(X)\n",
    "\n",
    "plt.scatter(X, y, alpha=0.75, edgecolors='black', label='Actual Value')\n",
    "plt.scatter(X, predictions, alpha=0.75, edgecolors='black', label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Non-Linear Dataset\n",
    "We will create a dummy dataset with $1$ feature and $1$ target variable. There will be a non-linear relationship between the feature and the target, and with some noise added to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total data\n",
    "m = 100\n",
    "# feature\n",
    "X = 6 * np.random.rand(m, 1) - 3\n",
    "# target\n",
    "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Scatter plot of X (feature) and y (target)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting $X$ into polynomial form. For this example, we will convert it to a $3$ degree polynomial. We will use the `PolynomialFeatures` class from `sklearn` and use the `degree` parameter to set the desired degree."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly[0:3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_poly = scaler.fit_transform(X_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly[0:3, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model3.predict(X_poly)\n",
    "\n",
    "plt.scatter(X, y, alpha=0.75, edgecolors='black', label='Actual Value')\n",
    "plt.scatter(X, predictions, alpha=0.75, edgecolors='black', label='Predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('./data/real_estate.xlsx')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 4:7]\n",
    "X.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, -1]\n",
    "y.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, shuffle=True, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=1)\n",
    "poly.fit(X_train)\n",
    "\n",
    "X_train = poly.transform(X_train)\n",
    "X_test = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(\n",
    "    fit_intercept=False,\n",
    "    copy_X=True,\n",
    "    n_jobs=8,\n",
    "    positive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training RMSE: ', np.sqrt(mean_squared_error(y_train, train_preds)))\n",
    "print('Test RMSE: ', np.sqrt(mean_squared_error(y_test, test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_10 = model.predict([X_test[10, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Actual Value: ', y_test.iloc[10])\n",
    "print('Prediction: ', pred_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y) - np.min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fb3c4fd9fe25374e0159eca8b8e2d468e8cbc895c30c0bc56e2d3921906cc884"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
